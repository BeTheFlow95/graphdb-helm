#
# Main configuration file
#
# To override single property use --set
# To override multiple, provide another values-override.yaml with the -f flag
# See https://helm.sh/docs/chart_template_guide/values_files/
#

# K8S API versions differ on Kubernetes and local Minikube installation.
# Please, refer to: https://kubernetes.io/blog/2019/07/18/api-deprecations-in-1-16/
versions:
  api: apps/v1
  service: v1
  ingress: extensions/v1beta1
  deployment: apps/v1
  secret: v1
  configmap: v1
  volume: v1
  job: batch/v1
  daemon: apps/v1
  pvc: v1
  pv: v1

# Top lvl flat for easier maintenance
images:
  kong: kong:2.1-alpine
  graphdb: docker-registry.ontotext.com/graphdb-ee:9.8.0-HOSTS-TR3-adoptopenjdk11
  busybox: busybox:1.31
  #TODO: Why this does not work with apline container??
  alpine: docker-registry.ontotext.com/graphdb-ee:9.8.0-HOSTS-TR3-adoptopenjdk11

####### DEPLOYMENT CONFIGURATIONS #######
deployment:
  # -- Defines the policy with which components will request their image.
  imagePullPolicy: IfNotPresent
  # Secret used to pull Docker images. Uncomment to use it.
  # Important: Must be created beforehand
  # imagePullSecret: maven-ontotext

  # -- The storage place where components will read/write their persistent data in case the default
  # persistent volumes are used. They use the node's file system.
  storage: /data
  # -- The hostname and protocol at which the graphdb will be accessible.
  # Needed to configure ingress as well as some components require it to properly render their UIs
  protocol: http
  # Important: This should be a resolvable hostname, not an IP address!
  host: localhost

  # Configures SSL termination on ingress level.
  # See https://kubernetes.github.io/ingress-nginx/examples/tls-termination/
  tls:
    # -- Feature toggle for SSL termination. Disabled by default.
    enabled: false
    # -- Name of a Kubernetes secret object with the key and certificate.
    # If TLS is enabled, it's required to be provided, depending on the deployment.
    secretName:

  # -- Ingress related configurations
  ingress:
    # -- Sets the maximum size for all requests to the underlying Nginx
    maxRequestSize: 512M
    # -- Default timeouts in seconds for the underlying Nginx.
    timeout:
      connect: 5
      read: 60
      send: 60

# KONG API gateway configurations.
# This gateway sits behind the ingress and exposes the rest of the components.
# By default Kong is deployed without database, e.g. stateless mode.
kong:
  # -- Reference to a configuration map with Kong configurations as environment variables.
  # Override if you need to further configure Kong's system.
  # See https://docs.konghq.com/2.0.x/configuration/
  configmap: kong-configmap
  # -- Reference to a configuration map containing declarative Kong configuration for
  # services and routes. This is the DB-less config.
  # See https://docs.konghq.com/1.5.x/db-less-admin-api/#declarative-configuration
  servicesConfigmap: kong-services-configmap
  # -- Overwrite if you want to deploy Kong on a non-standard port, such as instances
  # where you want to have two different installations on the same hardware.
  port:
    nodePort: 31122
  # -- Global timeout configurations for all services. Values are in milliseconds.
  timeout:
    connect: 60000
    read: 60000
    write: 60000
  # -- Memory cache size configuration for Kong in DB-less mode.
  # Tune according to the given resource limits.
  # See https://docs.konghq.com/2.0.x/configuration/#mem_cache_size
  memCacheSize: "64m"
  # -- Amount of Nginx worker processes. This affects how much memory will be consumed.
  # The auto value will determine the workers based on the available CPUs
  workers: auto
  # Default resource limitations.
  resources:
    limits:
      memory: 2048Mi
  # Schedule and assign on specific node. By default, no restrictions are applied.
  # See https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/
  nodeSelector: {}

# GraphDB database configurations
graphdb:
  # -- Cluster topology to be used. Possible values: standalone, 1m_3w, 2m3w_rw_ro, 2m3w_muted.
  # standalone - Launches single instance of GraphDB with a preconfigured worker repository. Masters and workers count is controlled by mastersCount and workersCount properties
  # 1m_3w - 1 master and multiple workers. https://graphdb.ontotext.com/documentation/enterprise/ee/setting-up-a-cluster-with-one-master.html
  # 2m3w_rw_ro - 2 masters, one of which is read only and multiple workers. https://graphdb.ontotext.com/documentation/enterprise/ee/setting-up-a-cluster-with-a-second-readonly-master.html
  # 2m3w_muted - 2 masters, one of which is muted and multiple workers. https://graphdb.ontotext.com/documentation/enterprise/ee/setting-up-a-cluster-with-multiple-masters-with-dedicated-workers.html
  # Note: If "standalone" is selected, the launched instance will use master-1 properties, but a worker repository will be created!
  topology: "2m3w_rw_ro"
  clusterConfig:
    # -- Describes how the masters and workers are linked in the format master-X -> worker-Y. Required only for 2m3w_muted topology.
    masterWorkerMapping:
      - master-1 -> worker-1
      - master-1 -> worker-2
      - master-2 -> worker-3
      - master-2 -> worker-4
    # -- Describes which masters will be set as read only. Required only for 2m3w_rw_ro topology.
    readOnlyMasters:
      - master-2
    # -- Describes which masters will be set as muted. Required only for 2m3w_muted topology.
    mutedMasters:
      - master-2
    # -- Describes which masters will be linked as sync peer. Required for 2m3w_rw_ro and 2m3w_muted topology.
    syncPeersMapping:
      - master-1 <-> master-2
    workersCount: 4
    mastersCount: 2
    #TODO: generate random if not present
    # -- A secret used for secure communication amongst the nodes in the cluster.
    clusterSecret: s3cr37

  masters:
    # -- The repository name to be created for all masters.
    # This repository will be initialized during of Helm's post install hooks.
    repository: test
    # -- Reference to a configuration map containing a repository 'config.ttl' file used for repository
    # initialization in the post install hook. For reference see https://graphdb.ontotext.com/documentation/standard/configuring-a-repository.html
    repositoryConfigmap: graphdb-repo-default-configmap
    # -- Reference to a secret containing 'graphdb.license' file to be used by master nodes.
    # This is a required secret without which GraphDB won't operate if you use SE/EE editions.
    # Important: Must be created beforehand
    license: graphdb-license
    # -- Java arguments with which master instances will be launched. GraphDB configuration properties can also be passed here in the format -Dprop=value
    java_args: " -Xmx4G -XX:MaxRAMPercentage=70 -XX:+UseContainerSupport"
    # -- Schedule and assign on specific node for ALL masters. By default, no restrictions are applied. This can be specified per instance in the nodes section.
    # See https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/
    nodeSelector: {}
    # -- Specific GraphDB master instances configurations. Supported properties for per node configuration are: license, java_args, graphdb_properties
    nodes:
      - name: master-1
        java_args: " -Xmx4G -XX:MaxRAMPercentage=70 -XX:+UseContainerSupport"
        nodeSelector: {}
        license: graphdb-license
    # -- Below are minimum requirements for data sets of up to 50 million RDF triples
    # For resizing, refer according to your GraphDB version documentation
    # For EE see http://graphdb.ontotext.com/documentation/enterprise/requirements.html
    resources:
      limits:
        memory: 4Gi
      requests:
        memory: 2Gi
    # -- Persistence configurations.
    # By default, Helm will use a PV that reads and writes to the host file system.
    persistence:
      # -- Name reference of a persistent volume to which the claim will try to attach.
      # Example result: graphdb-master-default-worker-1-pv
      volumeNamePrefix: graphdb-master-default
      storageClassName: standard
      # -- Storage size request for each master. The persistent volume has to be able to satisfy the size.
      storage: 10G

  workers:
    # -- The repository name to be created for all workers.
    # This repository will be initialized during of Helm's post install hooks.
    repository: test
    # -- Reference to a configuration map containing a repository 'config.ttl' file used for repository
    # initialization in the post install hook. For reference see https://graphdb.ontotext.com/documentation/standard/configuring-a-repository.html
    repositoryConfigmap: graphdb-worker-repo-default-configmap
    # -- Reference to a secret containing 'graphdb.license' file to be used by worker nodes.
    # This is a required secret without which GraphDB won't operate if you use SE/EE editions.
    # Important: Must be created beforehand
    license: graphdb-license
    # -- Java arguments with which worker instances will be launched. GraphDB configuration properties can also be passed here in the format -Dprop=value
    java_args: " -Xmx2G -XX:MaxRAMPercentage=70 -XX:+UseContainerSupport"
    # -- Schedule and assign on specific node for ALL workers. By default, no restrictions are applied. This can be specified per instance in the nodes section.
    # See https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/
    nodeSelector: {}
    # -- Specific GraphDB worker instances configurations. Supported properties for per node configuration are: license, java_args, graphdb_properties
    nodes:
        - name: worker-1
          license: graphdb-license
          master: master-1
        - name: worker-2
          java_args: " -Xmx1G -XX:MaxRAMPercentage=70 -XX:+UseContainerSupport"
          nodeSelector: {}
    # -- Persistence configurations.
    # By default, Helm will use a PV that reads and writes to the host file system.
    persistence:
      # -- Name reference prefix of a persistent volume to which the claim will try to attach.
      # Example result: graphdb-worker-default-worker-1-pv
      volumeNamePrefix: graphdb-worker-default
      storageClassName: standard
      # -- Storage size request for each worker. The persistent volume has to be able to satisfy the size.
      storage: 10G
      # -- Reference to a configuration map containing a worker node repository 'config.ttl' file
      # used for initialization in the post install hook.
      repositoryConfigmap: graphdb-worker-repo-default-configmap
      # Extra arguments passed to GDB_JAVA_OPTS environment variable
      # See http://graphdb.ontotext.com/documentation/enterprise/configuring-graphdb.html
      # Note: Same as for the master node

    # -- Below are minimum requirements for data sets of up to 50 million RDF triples
    # For resizing, refer according to your GraphDB version documentation
    # For EE see http://graphdb.ontotext.com/documentation/enterprise/requirements.html
    # Note: Same as for the master node
    resources:
      limits:
        memory: 4Gi
      requests:
        memory: 2Gi
  # Reference to a configuration map with GraphDB specific configurations.
  # Injected as environment variables.
  #configmap: graphdb-configmap
  # GraphDB workbench configurations
  workbench:
    # -- This is the sub path at which GraphDB workbench can be opened.
    # Should be configured in the API gateway (or any other proxy in front)
    subpath: /graphdb

  backupRestore:
    # -- Cron Schedule for auto backup. Creates an automatic backup, stored in the backup-pv
    # (default folder - /data/graphdb-backups).
    # The backups are saved in format MM-DD-YYYY-hh-mm
    # TODO: Add PV options for backups
    auto_backup: "* 0 * * *"
    # -- Cleans up the backups directory.
    # Makes sure that there is a limit of the stored backups.
    # Each or both of backups_count and backups_max_age could be used.
    cleanup_cron: "* 1 * * *"
    # -- Max number of backup dirs saved.
    backups_count: "5"
    # -- Max number of days for backups.
    backup_max_age: "5"
    # -- A future date at which we want to trigger a backup. Must be given in format DD.MM.YYYY hh:mm
    # Please bear in mind that there could be a time difference with the kubernetes environment
#    trigger_backup: "31.03.2021 14:52"
    # -- A future date at which we want to trigger a restore. Works only with a cluster with workers.
    # For a standalone the restore is called from an init container. Must be given in format DD.MM.YYYY hh:mm
    trigger_restore: "31.03.2021 14:50"
    # -- The name of the backup directory we want to restore.
    # Must be given in format MM-DD-YY-hh-mm, where MM-DD-YY-hh-mm is your backup directory
    restore_from_backup: "03-31-2021-14-47"

  # -- Tools for loading, scanning and repairing data in repos
  tools:
    # -- Tool to preload data in a chosen repo
    # https://graphdb.ontotext.com/documentation/enterprise/loading-data-using-preload.html
    preload:
      # -- If trigger is set to true, then the preload tool will be run while initializing the deployment
      # Don't forget to add repo config file(should be named config.ttl) and RDF data file to the graphdb-preload-data-pv
      # (default pv is: /data/graphdb-worker-preload-data)
      trigger: true
      # -- Options to add to the command
      # possible flags: -f, -p, -r
      flags: "-f"
      rdfDataFile: "geonames_europe.ttl "
    # -- Tool to preload data in a chosen repo
    # https://graphdb.ontotext.com/documentation/enterprise/loading-data-using-the-loadrdf-tool.html
    loadrdf:
      # -- If trigger is set to true, then the loadrdf tool will be run while initializing the deployment
      # Don't forget to add repo config file(should be named config.ttl) and RDF data file to the graphdb-preload-data-pv
      # (default pv is: /data/graphdb-worker-preload-data)
      trigger: false
      # -- Options to add to the command
      # possible flags: -f, -p
      flags: "-f"
      rdfDataFile: "geonames_europe.ttl "
    # -- Tool for scanning and repairing data
    # See https://graphdb.ontotext.com/documentation/enterprise/storage-tool.html
    storage_tool:
      # -- If trigger is set to true, then the storage tool will be run while initializing the deployment
      trigger: false
      # -- commands to run the storage-tool with
      command: "scan"
      # -- repo to run command on
      repository: "repo-test-1"
      # -- additional options to run the storage-tool with
      options: ""
